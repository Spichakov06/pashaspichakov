import nltk
from nltk.corpus import stopwords,gutenberg
from nltk.probability import FreqDist
import matplotlib.pyplot as plt
import string

nltk.download('gutenberg')
nltk.download('stopwords')
text=gutenberg.words('shakespeare-hamlet.txt')
print("\nЗагальна кількість слів у тексті:",len(text))
fdist=FreqDist(text)
top_ten=fdist.most_common(10)
print("\nТоп-10 слів в тексті (враховуючи артиклі та пунктуацію):")
for word, count in top_ten:
    print(f"{word:<10} {count:>5}")
words_raw=[w for w,_ in top_ten]
counts_raw=[c for _,c in top_ten]
plt.figure(figsize=(10,5))
plt.bar(words_raw,counts_raw,color='skyblue')
plt.title("Топ-10 слів (з артиклями та пунктуацією)")
plt.xlabel("Слова")
plt.ylabel("Частота")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
stop_words=set(stopwords.words("english"))
punct=set(string.punctuation)
cleaned_words=[w.lower() for w in text if w.lower() not in stop_words and w not in punct and w.isalpha()]
fdist_clean=FreqDist(cleaned_words)
top_ten_clean=fdist_clean.most_common(10)
print("\nТоп-10 слів після очищення (без артиклів та пунктуації) :")
for word, count in top_ten_clean:
    print(f"{word:<10} {count:>5}")
words_clean=[w for w,_ in top_ten_clean]
counts_clean=[c for _,c in top_ten_clean]
plt.figure(figsize=(10,5))
plt.bar(words_clean, counts_clean,color='salmon')
plt.title("Top 10 слів після видалення стоп-слів і пунктуації")
plt.xlabel("Слова")
plt.ylabel("Частота")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
